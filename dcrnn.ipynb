{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataloader import CINE2DT\n",
    "from model.model_pytorch import CRNN_MRI\n",
    "from utils import multicoil2single, compressed_sensing as cs\n",
    "from utils.dnn_io import to_tensor_format, from_tensor_format\n",
    "from trainer_dcrnn_test import prep_input\n",
    "from torch.autograd import Variable\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'  # 指定使用 GPU 1 和 GPU 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import types\n",
    "\n",
    "# def get_config():\n",
    "#     \"\"\"\n",
    "#     从config_dcrnn.yaml文件中读取配置信息并返回\n",
    "#     返回:\n",
    "#     config (dict): 包含配置信息的字典，符合CRNN_MRI类初始化等所需的配置结构\n",
    "#     \"\"\"\n",
    "#     config_path = \"/nfs/zzy/code/k_gin_base/config_dcrnn.yaml\"\n",
    "#     with open(config_path, 'r') as file:\n",
    "#         full_config = yaml.safe_load(file)\n",
    "\n",
    "#     # 提取network部分中CRNN_MRI相关配置，假设其结构如你所述\n",
    "#     network_config = full_config.get(\"network\", {}).get(\"CRNN_MRI\", {})\n",
    "#     return network_config\n",
    "class ConfigWrapper:\n",
    "    def __init__(self, config_data):\n",
    "        # 使用types.SimpleNamespace将字典转换为可通过属性访问的对象形式\n",
    "        self.CRNN_MRI = types.SimpleNamespace(**config_data)\n",
    "\n",
    "\n",
    "def get_config_model():\n",
    "    \"\"\"\n",
    "    从config_dcrnn.yaml文件中读取配置信息并返回\n",
    "    返回:\n",
    "    config (ConfigWrapper): 包含配置信息的包装类实例，其CRNN_MRI属性对应包含模型初始化参数的字典，符合CRNN_MRI类初始化的配置结构期望\n",
    "    \"\"\"\n",
    "    config_path = \"/nfs/zzy/code/k_gin_base/config_dcrnn.yaml\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        full_config = yaml.safe_load(file)\n",
    "\n",
    "    # 提取network部分中CRNN_MRI相关配置，假设其结构如你所述\n",
    "    network_config = full_config.get(\"network\", {}).get(\"CRNN_MRI\", {})\n",
    "    return ConfigWrapper(network_config)\n",
    "\n",
    "def get_config_data_test():\n",
    "    \"\"\"\n",
    "    从config_dcrnn.yaml文件中读取配置信息并返回\n",
    "    返回:\n",
    "    config (dict): 完整的配置信息字典，符合各个类实例化及相关功能对配置的需求\n",
    "    \"\"\"\n",
    "    config_path = \"/nfs/zzy/code/k_gin_base/config_dcrnn.yaml\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# 定义函数来加载训练好的模型以及对应的测试数据集\n",
    "def load_model(model_path, config):\n",
    "    \"\"\"\n",
    "    加载训练好的模型\n",
    "    参数:\n",
    "    model_path (str): 模型文件（.pth）的路径\n",
    "    config: 配置参数，符合CRNN_MRI类构造函数要求的格式\n",
    "    返回:\n",
    "    model (torch.nn.Module): 加载好权重的模型对象\n",
    "    \"\"\"\n",
    "    model = CRNN_MRI(config)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "class DataConfigWrapper:\n",
    "    def __init__(self, data_dict):\n",
    "        for key, value in data_dict.items():\n",
    "            setattr(self, key, value)\n",
    "            \n",
    "def load_test_data(config):\n",
    "    \"\"\"\n",
    "    加载测试数据集\n",
    "    返回:\n",
    "    test_loader (DataLoader): 测试数据的数据加载器\n",
    "    \"\"\"\n",
    "    # test_ds = CINE2DT(config=None, mode='val')  # 这里的config参数需根据实际情况传入正确配置，暂时设为None示例\n",
    "    # test_ds = CINE2DT(config=config.data, mode='val')\n",
    "    wrapped_data_config = DataConfigWrapper(config)\n",
    "    # test_ds = CINE2DT(config=config, mode='val')\n",
    "    # 然后将包装后的配置对象传入CINE2DT类构造函数\n",
    "    test_ds = CINE2DT(config=wrapped_data_config, mode='val')\n",
    "    test_loader = DataLoader(dataset=test_ds, num_workers=2, drop_last=False, batch_size=2, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义函数用于显示原始图片、重建图片以及它们之间的差异（例如计算差值或者使用其他对比指标来可视化差异，这里简单展示计算差值的方式）：\n",
    "# def display_images(original_image, reconstructed_image):\n",
    "#     \"\"\"\n",
    "#     显示原始图片、重建图片以及它们的差异图像\n",
    "#     参数:\n",
    "#     original_image (torch.Tensor 或 np.ndarray): 原始图片数据\n",
    "#     reconstructed_image (torch.Tensor 或 np.ndarray): 重建图片数据\n",
    "#     \"\"\"\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "#     # 显示原始图片\n",
    "#     axes[0].imshow(original_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "#     axes[0].set_title('Original Image')\n",
    "#     axes[0].axis('off')\n",
    "\n",
    "#     # 显示重建图片\n",
    "#     axes[1].imshow(reconstructed_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "#     axes[1].set_title('Reconstructed Image')\n",
    "#     axes[1].axis('off')\n",
    "\n",
    "#     # 计算并显示差异图像（简单计算差值）\n",
    "#     diff_image = np.abs(original_image.squeeze().cpu().numpy() - reconstructed_image.squeeze().cpu().numpy())\n",
    "#     axes[2].imshow(diff_image, cmap='gray')\n",
    "#     axes[2].set_title('Difference Image')\n",
    "#     axes[2].axis('off')\n",
    "\n",
    "#     plt.show()\n",
    "def display_images(original_image, reconstructed_image):\n",
    "    \"\"\"\n",
    "    显示原始图片、重建图片及其差异。\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # # 转换为适合显示的格式（取复数模值）\n",
    "    # original_image_display = np.abs(original_image.squeeze().cpu().numpy())\n",
    "    # reconstructed_image_display = np.abs(reconstructed_image.squeeze().cpu().numpy())\n",
    "    # difference_image_display = np.abs(original_image_display - reconstructed_image_display)\n",
    "    # 保证输入数据为 NumPy 格式\n",
    "    original_image = original_image.cpu().numpy()\n",
    "    reconstructed_image = reconstructed_image.cpu().numpy()\n",
    "\n",
    "    # # 确保两个数据的形状一致（取批次中第一张图像）\n",
    "    # original_image_display = np.abs(original_image[0])  # 假设取第一张图片\n",
    "    # reconstructed_image_display = np.abs(reconstructed_image[0])  # 假设取第一张图片\n",
    "    # 提取第一个 batch 的第一个切片\n",
    "    original_image_display = np.abs(original_image[0, 0])  # [192, 192]\n",
    "    reconstructed_image_display = np.abs(reconstructed_image[0, 0])  # [192, 192]\n",
    "\n",
    "    # 差异图片\n",
    "    difference_image_display = np.abs(original_image_display - reconstructed_image_display)\n",
    "\n",
    "    # 显示原始图片\n",
    "    axes[0].imshow(original_image_display, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 显示重建图片\n",
    "    axes[1].imshow(reconstructed_image_display, cmap='gray')\n",
    "    axes[1].set_title('Reconstructed Image')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # 显示差异图片\n",
    "    axes[2].imshow(difference_image_display, cmap='gray')\n",
    "    axes[2].set_title('Difference Image')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_config: {'train_subjs': '/nfs/zzy/data/k_gin_data/k_cine_multicoil_training.npy', 'train_maps': '/nfs/zzy/data/k_gin_data/csm_cine_multicoil_training.npy', 'val_subjs': '/nfs/zzy/data/k_gin_data/k_cine_multicoil_test.npy', 'val_maps': '/nfs/zzy/data/k_gin_data/csm_cine_multicoil_test.npy', 'mask_root': '/nfs/zzy/code/k_gin_base/masks/VISTA/e_192x18_acs4_R4.mat', 'data_root': '/nfs/zzy/data/k_gin_data', 'mask_pattern': 'VISTA', 'acc_rate': [4], 'dtype': 'complex128', 'training_patch_time': 16, 'only_infer': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_291105/239937898.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m data_config \u001b[38;5;241m=\u001b[39m data_test_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, {})  \u001b[38;5;66;03m# 提取data部分配置信息，若不存在则返回空字典\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_config:\u001b[39m\u001b[38;5;124m'\u001b[39m,data_config)\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m load_test_data(data_config)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# test_loader = load_test_data(data_test_config)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 将模型加载到相同设备\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, config)\u001b[0m\n\u001b[1;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m CRNN_MRI(config)\n\u001b[1;32m     60\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[0;32m---> 61\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     62\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "# 主逻辑代码来调用上述函数，实现加载模型、数据，并进行图片显示\n",
    "# 模型文件路径，替换为你实际保存的模型文件路径\n",
    "# model_path = '/nfs/zzy/code/k_gin_base/experiments/test_dcrnn/model_101.pth'\n",
    "# model_path = '/nfs/zzy/code/k_gin_base/experiments/test_dcrnn_test/model_241.pth'\n",
    "# model_path = '/nfs/zzy/code/k_gin_base/models/dc_rnn_test/final_model.pth'\n",
    "model_path = '/nfs/zzy/code/k_gin_base/experiments/test_dcrnn_test/model_241.pth'\n",
    "model_config  = get_config_model()\n",
    "data_test_config = get_config_data_test()\n",
    "data_config = data_test_config.get('data', {})  # 提取data部分配置信息，若不存在则返回空字典\n",
    "print('data_config:',data_config)\n",
    "model = load_model(model_path,model_config)\n",
    "test_loader = load_test_data(data_config)\n",
    "# test_loader = load_test_data(data_test_config)\n",
    "# 将模型加载到相同设备\n",
    "model = model.to(device)\n",
    "\n",
    "for i, (kspace, coilmaps, sampling_mask) in enumerate(test_loader):\n",
    "    if i >= 5:  # 只显示前5个示例图片，可根据需要调整数量\n",
    "        break\n",
    "    ref_kspace, ref_img = multicoil2single(kspace, coilmaps)\n",
    "    ref_img = ref_img.squeeze()  # 去除批次维度\n",
    "\n",
    "    # 假设这里的处理逻辑和训练时的prep_input函数等保持一致，进行必要的数据预处理\n",
    "    im_und, k_und, mask, im_gnd = prep_input(ref_img, acc=4.0)  # acc参数需根据实际训练情况传入正确值\n",
    "    # im_u = torch.from_numpy(to_tensor_format(im_und)).unsqueeze(0).type(torch.FloatTensor)  # 添加批次维度\n",
    "    # k_u = torch.from_numpy(to_tensor_format(k_und)).unsqueeze(0).type(torch.FloatTensor)\n",
    "    # mask = torch.from_numpy(to_tensor_format(mask)).unsqueeze(0).type(torch.FloatTensor)\n",
    "    # 数据也需要移到相同设备\n",
    "    im_u = Variable(im_und.type(Tensor)).to(device)\n",
    "    k_u = Variable(k_und.type(Tensor)).to(device)\n",
    "    mask = Variable(mask.type(Tensor)).to(device)\n",
    "    gnd = Variable(im_gnd.type(Tensor)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_image = model(im_u, k_u, mask, test=True)\n",
    "    # reconstructed_image-shape: torch.Size([2, 2, 192, 192, 18])\n",
    "    # ref_img-shape: torch.Size([2, 18, 192, 192])\n",
    "    print('reconstructed_image-shape-1:',reconstructed_image.shape)\n",
    "    print('ref_img-shape:',ref_img.shape)\n",
    "    # 对 reconstructed_image 取模值，合并通道\n",
    "    reconstructed_image = torch.sqrt(reconstructed_image[:, 0, ...] ** 2 + reconstructed_image[:, 1, ...] ** 2)  # [2, 192, 192, 18]\n",
    "\n",
    "    # 转置 reconstructed_image 的维度，匹配 ref_img 的形状\n",
    "    reconstructed_image = reconstructed_image.permute(0, 3, 1, 2)  # [2, 18, 192, 192]\n",
    "    print('reconstructed_image-shape-2:',reconstructed_image.shape)\n",
    "    display_images(ref_img, reconstructed_image.squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
